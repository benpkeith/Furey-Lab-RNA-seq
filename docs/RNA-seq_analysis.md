2020.07.13 - Ben Keith

# Downstream RNA-seq Analysis Tutorial

This is a basic tutorial for performing downstream analyses and plotting such as:

- Differential expression analysis (DESeq)
- Batch and covariate correction
- MA plots
- Volcano plots
- Heatmaps (Hierarchical Clustering)
- Boxplots
- Venn plots
- Principal Components Analysis (PCA)
- Enrichment analyses (both within R and externally through tools such as Enrichr)

This analysis concentrates on the analysis of human data, but files for mouse data (mm10) can be changed out to produce the exact same outputs.

Other useful tutorials with more in depth information on some of the tools used here:

- [DESeq2](http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)
- [Analysis of RNA-seq data](https://bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html)
- [Enhanced Volcano](https://www.bioconductor.org/packages/release/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html)
- [PCAtools](https://bioconductor.org/packages/release/bioc/vignettes/PCAtools/inst/doc/PCAtools.html)
- [Complex Heatmap](https://jokergoo.github.io/ComplexHeatmap-reference/book/) and Complex Heatmap [FAQs](https://bioconductor.org/packages/release/bioc/vignettes/ComplexHeatmap/inst/doc/most_probably_asked_questions.html)

### Which R version (3.6.0), installing packages, and setting up the analysis environment

At the time of writing, all packages used in this tutorial are compatible with R 3.6.X. I recommend R 3.6.0, but with the release of R 4.0, bioconductor packages will gradually shift to R > 4.0.

All packages will be installed through:

```
install.packages('packageName')
```

or

```
BiocManager::install('packageName')
```

or

```
devtools::install_github('git/package')
```

##### Ben's function file

For some of the analyses mentioned here, you will need to source a file into your environment to have access to a number of functions. The file, called _RNAseqFunctions.R_ is in the downstreamAnalysis folder of the snakemake_RNA git. Once in R, use the command:

```
source("path/to/RNAseqFunctions.R")
```

The first time you try to do this, will probably get prompts that a specific package is not installed. Keep installing the required packages and resourcing the file until everything loads correctly and the functions are listed in your global environment.

##### Count, Metadata, lookup Files, and filtering samples based on some criteria.

To perform this analysis, you will need a count a metadata file containing information about each of your samples. The count file may have already been generated by the snakemake RNA pipeline, although a custom count matrix file can be generated by following the instructions in the _Custom_count_matrix_generation.md_ tutorial. The links to the RNA-seq analysis and DESeq2 documentation above provide more information about how these files should be formatted, but I use a couple of custom functions for importing these files into the environment:

```
coldata <- read_delim("metadataFile.txt", delim = "\t", col_names = TRUE)
coldata <- tibble2dataframe(coldata)
cts <- read_delim("countMatrix.txt", delim = "\t", col_names = TRUE)
cts <- tibble2dataframe(cts); cts <- round(cts);

# THIS MUST RETURN TRUE!
all(rownames(coldata) == colnames(cts))
```

**For DESeq the rownames of the metadata table must equal the column names of the count file.**

By importing the data as a tibble, rather than a data frame, you can fix data type issues that might arise further downstream in the analysis. Some functions I use require a data frame, though, so I convert back to a data frame but retain the correct data type for each column.

The last pre-analysis piece you set up you will have do is regarding the import of a lookup file for converting ensembl IDs to gene IDs. The files _"GENOMEBUILD_ensembl2gene.txt"_, can be found in the downstreamAnalysis folder of the snakemake_RNA git repo and can be loaded into your environment like any other file:

```
ens2gene <- read.table(hg38_ensembl2gene.txt", sep="\t", header = TRUE)
```

For safety and compatibility with my functions, name this _ens2gene_. As well as gene ID conversion information, this file also provides gene biotype information for filtering specific genes, such as protein coding or lncRNAs, from you dataset.

Lastly, there is often a need to filter down your imported coldata and count file based on some criteria. I use a wrapper that filters both the coldata and count file based on some criteria in the coldata file, saving both objects into a list. For example, if you wanted to filter only Crohn's disease samples with a quality score (TIN) greater than 70, this would look like:

```
# NOTE: In this example coldata file, disease status was found under the column
# "status" and TIN score under the column "TIN_med"
# NOTE: The matchingColumn argument point to the name of the column in the
# coldata that links to the column names in the count file. i.e. the column
# the allows the two objects to be matched.
# NOTE: The filterString argument must be wrapped by the "quote()" function. The
# syntax of this filter is standard for R subsetting, where "&" can be used for
# dependent conditions and "|" for independent conditions.
filteredData <- filterData(coldata, cts, matchingColumn = "sample",
  filterString = quote(status == "CD" & TIN_med > 70))

# If you're not comfortable working with list objects, separate out the list
# like so
cts.filtered <- cts.filterData(filteredData)
coldata.filtered <- coldata.filterData(filteredData)
```

### Downstream analysis

Going into this section, I assume you have your **count matrix**, **metadata**, **lookup file** and **function file** in your environment.

##### DESeq2

The example below provides very simple DESeq analysis example when you have identified the condition or variable that you want to test for. DESeq2 is a very well documented tools, and more information can be found in Mike's vignettes.

```
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ status)

dds <- DESeq(dds)

# The contrast argument here is ensuring that +ve log2FC means higher
# in CD samples.
results(dds, contrast = c("status", "CD", "NIBD"))

# Adding gene ID and biotype columns to our results output
res$ensembl <- rownames(res)
res <- join(as.data.frame(dds), ens2gene, by="ensembl")

# Ordering the output by adjusted p-value
res <- res[order(res$padj),]
```

In some scenarios, there will be a number of covariates in your design formula and sometimes there may be a number of numerical covariates. To avoid issues. it is important that these numerical covariates are on the same scale. This can be easily done using something like the below:

```
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ batch + age + TIN + status)

dds$age <- centerAndScale(dds$age)
dds$TIN <- centerAndScale(dds$TIN)
dds <- DESeq(dds, minRep=Inf)
```

Your results can be exported using a command like below:

```
write.table(res, file = "DESeq_results.txt", sep="\t", quote=FALSE, col.names=NA)
```

##### Quick word on batches and corrections
DESeq should be performed **without any normalization or correction** of the data. later I will mention a few different ways that batches and covariates can be corrected, but the count matrix that is input into DESeq should not be modified. Instead any covariates or batches should be entered into the DESeq design formula.

#### Volcano and MA plots

Using your DESeq results object, _res_, you plot the data in a number of useful ways. A couple of plots we regularly use are volcano and MA plots.

For volcano plots, I use the package EnhancedVolcano, which is really well documented and can probably be modified for anything you're trying to plot.

```
EnhancedVolcano(res, lab = res$gene_id, pLabellingCutoff = 2E-61,
                x = "log2FoldChange", y = "padj", ylab = bquote(~-Log[10]~italic(P)~adjusted),
                FCcutoff = 1, pCutoff = 0.05, colAlpha = .8, pointSize = 1,
                drawConnectors = TRUE, widthConnectors = 0.2, legendPosition = "bottom",
                title = "CL vs IL",
                subtitle = "FC thres = 1, pCutoff = 0.05, plabelling , 2E-61 ",
                legendLabels = c("NS", bquote(~-Log2~FC), bquote(~italic(P)~"adj"),
                                 bquote(~italic(P)~adj~"&"~-Log2~FC)),
                ggsave("volcano_ILCL.pdf", device = "pdf"))
```

<img src="plots/volcano_ILCL.png" alt="heatmap" width="600"/>

Other potential parameters of interest:
- selectLab - Allows you to pass a vector of genes names to label specific genes
- colCustom - pass a vector of color names of hex values to color points to a custom filter

I produce MA plots using ggpubr. For a quick glance, you can produce MA plots straight after performing DESeq using the function:

```
plotMA(res)
```

For nicer looking plots, we can use the ggmaplot function:

```
maplot <- ggmaplot(res, fdr = 0.05, fc = 1, size = 1,
                   palette = c("red2", "royalblue", "darkgray"),
                   genenames = as.vector(res$gene_id),
                   ggtheme = ggplot2::theme_minimal(),
                   legend="top", font.label = c("bold", 10),
                   label.rectangle = FALSE, font.legend = c("bold",12),
                   font.main = "bold",
                   top = 10)
maplot <- maplot + ylim(c(-10,10)) + ggsave("maplot_ILCL.png", device = "png")
```

<img src="plots/maplot_ILCL.png" alt="maplot" width="600"/>

Other potential parameters of interest:
- label.select - Here I am plotting the top 10 genes in terms of padj (top = 10), but you can select genes by passing them through the parameter label.select. At the time of writing, the version of ggpubr that I am using does not have this parameter available through the bioconductor version of ggpub, so you may need to install ggpubr from the developers github!

#### PCA

**NOTE** The example I am giving here is using my own custom PCA functions, but a recently released package called PCAtools (referenced at the top of this documentation) by the developer of Complex Heatmap should be used by the lab going forward. If you need to quickly produce a PCA plot, feel free to use the code below.

PCA can be performed as part of your QC as well as a part of the downstream analysis to visualize differences among your samples. PCA well detect large sources of variance within your dataset. With this in mind, a number of things can affect PCA and must be taken into account:

- Batch effects
- Uncorrected covariates (transcript integrity, specific cell-type proportion differences, sex, age)
- Number of genes as input
- outliers genes (genes anomalously highly expressed in one or a small subset of samples)

Along with the above, PCA assumes that your data is normally distributed, which means that the input data must be normalized and transformed. The below code will take you through from raw count data to a PCA plot using a subset of protein-coding genes where filtering has been performed to remove potential outlier genes. **For correcting for batch effects, refer to the _Batch effects_ section.**

```
# Data normalization
dds <- DESeqNormalize(counts = cts, coldata = coldata, designFormula = ~ status)

# Transform data
vsd <- transformData(dds, trans="vst", blind=TRUE)
vsd <- as.data.frame(assay(vsd))

# Threshold and filter genes by biotype
# hist(as.matrix(vsd)) to view the general distributions of values to select a normThres
# table(coldata$variable) to see how sample numbers break down. You want to select a value for
# sampleThres less than or equal to the LOWEST number of samples in the variable of interest to
# avoid filtering out group-specific genes.
# table(ens2gene$biotype) to view the possible biotypes that you could filter for.
vsd.pcThres <- thresholdBiotype(vsd, normThres = 5, sampleThres = 6, biotype = "protein_coding")

# Variance filter
vsd.pcThres.var <- varFilter(vsd.pcThres, variableGenes = 500)

#PCA
rnaSeqPCA(vsd.pcThres.var, coldata, color = "subtype", \
  savePlot = TRUE, saveTitle = "pca_ILCL", legend = TRUE, pointSize = 5, plotLabs = TRUE)

```
<img src="plots/pca_ILCL.png" alt="pcaplot" width="600"/>

rnaSeqPCA has a number of functions that may be useful:
- the _proportional_ flag can be set to creat a PCA plot that is proportions to the variation to the axes of interest.
- _x_ or _y_ parameters can be set to look at a specific PC, e.g. x = "PC2", y = "PC3" would plot PC2 vs PC3
- The _loadings_ flag can be set to TRUE to output PCA loadings for the top 5 PCs. The ens2gene object must be present in the environment as this function also binds gene names and biotypes.
- The _plotly_ flag can be set to TRUE to produce an interactive plots
- The _returnData_ flag can be set to TRUE and pointed into a variable to save the PC values for each sample, which is useful for performing correlation analyses of PCs and covariates.

#### Heatmaps and Hierarchical Clustering

The Complex Heatmaps package I use for heatmaps is very well documented (links at the top of the page). This is a brief example of how to produce a plot using this package, but the documentation for this package should be referenced for all available options and parameters.

```
# The starting point here is normalized/transformed data that may have been
# corrected (if necessary), with a subset of genes taken for clustering.
# I am used the same 500 genes used in the PCA plot above.

# scale/center data
z.mat <- t(scale(t(vsd.pcThres.var), center = TRUE, scale=TRUE))

# set the color scale for the heatmap
myPalette <- c("blue3", "ivory", "red3")
myRamp = colorRamp2(c(-2, 0, 2), myPalette)

# add variables of interest color annotations (this can be similarly done for the rows)
ann <- data.frame(Subtype = coldata.W$subtype, Status = coldata.W$status,
                  Age = coldata.W$ageSampleCollection)
annColors <- list(Age = colorRamp2(c(14,81), c("#9900cc", "#f8eb01")),
                     Subtype = c("CL"="#0000FF", "IL"="#F60000", "NIBDcolon"="#000000"),
                     Status = c("CD"="#0a9618", "NIBDcolon"="#000000"))
colAnn <- HeatmapAnnotation(df = ann, col = annColors, show_legend = TRUE,
                            annotation_height = 0.5, show_annotation_name = TRUE, annotation_name_side = "left")

#plotting
png("heatmap_ILCL.png")
Heatmap(z.mat, name="z-score", top_annotation=colAnn, col = myRamp,
        show_row_names = FALSE, show_column_names = FALSE, cluster_rows = TRUE,
        cluster_columns = TRUE, show_column_dend = TRUE, show_row_dend = TRUE,
        row_dend_reorder = TRUE, column_dend_reorder = TRUE,
        clustering_method_rows = "ward.D2", clustering_method_columns = "ward.D2",
        clustering_distance_rows = "euclidean", clustering_distance_columns = "euclidean")
dev.off()
```
<img src="plots/heatmap_ILCL.png" alt="heatmap" width="400"/>

#### Batch and covariate correction

Batch correction is a well documented and well commented topic across various vignettes on bioconductor and through numerous threads on biostars. Normally, you will want to perform these corrections when your data has been sequences across numerous batches, or when a significant proportion of the variation is attributed to some kind of technical or experimental artifact. Sometimes we can confidently assign values to these artifacts to easily correct them away using linear regression, but in other cases, these are tools we can use to calculate these covariates for us.

As a quick summary of some of the initial questions I had when first approaching batch correction:

**What correction do I need to do prior to DESeq?**

None. Raw counts should always be the input to DESeq and the batches/covariates that we would like to correct for should be included in the design formula. (NOTE: there are tools being released that _do_ perform correction to raw counts before DE tools, like [ComBat-seq](https://github.com/zhangyuqing/ComBat-seq). At the time of writing, I have no experience in using these tools, but the may before common/incorporated into DESeq2 in the future).

By including these covariates and batches in the design formula for DESeq, the output results will have taken these covariates into account when performing differential expression analyses.

**Can I use DESeq when I want to correct my data for things like PCA and hierarchical clustering?**

We can use DESeq to normalize our data, but we will have to use tools like [SVA (section 4)](https://bioconductor.org/packages/release/bioc/vignettes/sva/inst/doc/sva.pdf), [Combat (section 7)](https://bioconductor.org/packages/release/bioc/vignettes/sva/inst/doc/sva.pdf), or limma's ["removeBatchEffects"](https://rdrr.io/bioc/limma/man/removeBatchEffect.html) to correct our normalized and transformed data. There are certain scenarios when we prefer to use one tool over another, and this will be explained further in this section.

**Which batch correction tool do I use?**

...sva vs removeBatchEffects.

<ins>Accounting for batching and covariates in DESeq - **DESeq2 design formula**<ins/>

For all DESeq related issues and queries, the various documentation and vignettes that Mike has put out (along with him being really attentive to question on various forums) will almost certainly answer your question. This section is to briefly introduce how you might account for batches and covariates and how to deal with a particular scenario we encounter during the analysis of our colonic CD data.

Accounting for batches and covariates when performing DESeq is really easy. In an analysis where you would need to correct for batch while looking for differences across one variable, you would set up your analysis like this:

```
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ batch + status)

dds <- DESeq(dds)
```

By including batch in the design formula, DESeq will account for differences in batch when performing differential gene expression analysis. **Mike recommended placing the covariate of interest at the end of the design formula**

Numeric covariates can also be included design formula in the same way, **but it is important that these numeric covariates are on the same scale**. For example, we performed an analysis in the past where we included a proportion (0-1) and age (25-85) as covariates in our design formula. Since these are on different scales, this causes converge issues for DESeq's GLM, resulting is strange results that did not correlate with what we observed in our downstream analyses. Therefore, in scenarios like this, you get solve this issue be doing something like the below:

```
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ batch + IECAve + ageSampleCollection + status)

dds$IECAve <- centerAndScale(dds$IECAve)
dds$ageSampleCollection <- centerAndScale(dds$ageSampleCollection)
dds <- DESeq(dds, minRep=Inf)
```

The centerAndScale function is included in the function script, but for reference all this is doing is subtracting the mean and dividing by the standard deviation:

```
centerAndScale <- function(x) (x - mean(x)) / sd(x)
```

Although this allows to perform differential analyses taking into account batches and covariates, we need to perform additional steps for downstream analyses that involve visualization of our data (PCA, clustering).

<ins>Correcting for known Batches and technical covariates - **removeBatchEffects**<ins/>

For us, the most common way that we identify these factors is through initial PCAs. Sometimes these are more obvious (usually batch), but other times we may need to dig a bit deeper into our QC metrics to determine whether what we're seeing is due to underlying biology, or technical/experimental/acquisitional differences between our samples. Below is a simple example that can probably be applied to your data.

```
# Data normalization
dds <- DESeqNormalize(counts = cts, coldata = coldata, designFormula = ~ status)

# Transform data
vsd <- transformData(dds, trans="vst", blind=TRUE)
vsd <- as.data.frame(assay(vsd))

# Subset 500 most variable genes for PCA
vsd.var <- varFilter(vsd, variableGenes = 500)

rnaSeqPCA(vsd.var, coldata, color = "subtype")
```

PCA PLOT SUBTYPE

Although it looks like PC2 is driven by our variable of interest, something is going on here with PC1. By colouring the points by batch...

PCA PLOT BATCH

...we can clearly see that batch is driving PC1, and therefore drives a significant proportion of the variability within this dataset. Below I correct for this using a wrapper of limma's removeBatchEffects on data that has been normalized and transformed

```
# batch correction
batch <- coldata$batch
vsd.batch <- limmaCorrect(transData = vsd, batch = batch)

# Subset 500 most variable genes for PCA
vsd.batch.var <- varFilter(vsd.batch, variableGenes = 500)

rnaSeqPCA(vsd.batch.var, coldata, color = "subtype")
```

PCA PLOT BATCH CORRECTED SUBTYPE

It worth noting here that in some analyses, like our colonic tissue CD analysis, the batches are very heterogeneous and contain difference numbers of samples. In these analyses, where you would probably want to remove outlier samples or samples with low QC scores, it is worth performing the batch correction _before_ filtering these samples out. Hopefully be performing the analysis in this order, we increase our power for corrected these effects out of the data.

In some other, not so obvious scenarios, we may be able to detect covariates that are highly variable across our data, and therefore correlate with PCs. In the data used in the above examples, a covariate that we identified as highly variable was the proportion of Intestinal Epithelial Cells (IECs) that were predicted in our tissue samples through deconvolution analyses using DESeq's unmix function. The following is an example of how you might go above showing this significant correlation.

```
# The input here is the batch corrected data that was used in the previous examples
rnaSeqPCA(vsd.batch.var, coldata, color = "IECAve")
```

PCA PLOT BATCH CORRECTED IEC

```
# The return data argument allows you to perform correlation analyses between metadata
# and PC values for each sample.
pcaData <- rnaSeqPCA(vsd.batch.filt.var, coldata, color = "IECAve", returnData=TRUE)
cor.test(pcaData$PC2, pcaData$IECAve)
```

```
Pearson's product-moment correlation

data:  pcaData$PC2 and pcaData$IECAve
t = 5.268, df = 115, p-value = 6.511e-07
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
0.2819530 0.5763216
sample estimates:
    cor
0.4409181
```

From this, we can see that there is a significant correlation with IEC proportion, suggesting that we should correct for this! The correction line in our script here would look like:

```
batch <- coldata$batch; IEC <- coldata$IECAve
vsd.batch <- limmaCorrect(transData = vsd, batch = batch, covariate = IEC)
```

With a particularly heterogeneous dataset, we may want to correct for multiple covariates while retaining variation associated with a particular covariate. Here, our correction step would look something like this:

```
batch <- coldata$batch; IECAve <- coldata$IECAve; status <- coldata$status;
TIN_med <- coldata$TIN_median; age <- coldata$ageSampleCollection

# Note the use of the cbind function in the covariate argument and the
# model.matrix function in the design argument. This design argument means
# that we want to retain variation association with disease status.
vsd.BISAT <- limmaCorrect(transData = vsd, batch = batch,
  covariate = cbind(IECAve, age, TIN_med), design = model.matrix(~ status))
```

Unlike with DESeq, we do not need to worry too much about centering and scaling our numeric covariate as removeBatchEffect uses a closed form equation that should not fail to converge like the iterative GLM used by DESeq2.

Although for this example I have been using the output from limmaCorrect for PCA, this data frame can be used in analysis that would usually require a normalized and transformed dataset as input.

<ins>Correcting for unknown technical variation - **SVA**</ins>
